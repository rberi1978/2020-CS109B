{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109B Data Science 2: Advanced Topics in Data Science \n",
    "\n",
    "##  Project F: Measuring the Shape and Brightness of Galaxies with Neural Networks\n",
    "### Ideation 5\n",
    "### Group 75: Dmitry Vukolov, Ning Xu, Rohit Beri, Sunil Chomal\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Spring 2020**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Mark Glickman and Chris Tanner<br/>\n",
    "\n",
    "\n",
    "<hr style=\"height:2pt\">\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THIS CELL\n",
    "import requests\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "styles = requests.get(\n",
    "    \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\"\n",
    ").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> Outline </div> \n",
    "\n",
    "1. Overview\n",
    "2. Loading the Data\n",
    "3. Structure and Size of the Data\n",
    "4. Basic Statistics of the Data \n",
    "5. Visualization of the Image Data \n",
    "6. Distributions of the Labels and Numerical Attributes \n",
    "7. Parametric Image Generation\n",
    "8. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> Overview </div> \n",
    "\n",
    "<div style=\"border: 3px solid #800080; padding: 10px\"> \n",
    "\n",
    "## Creating Galaxy images using GalSim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> Part 1 </div> \n",
    "\n",
    "<div style=\"border: 3px solid #800080; padding: 10px\"> \n",
    "\n",
    "## GalSim Images with fixed Sigma and PSF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 0: Load the essential libraries </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load useful libraries\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Import h5py for reading h5 files\n",
    "import h5py\n",
    "\n",
    "# Load galsim for data generation\n",
    "import galsim\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Tweak plot resolution and styling\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "sns.set(style=\"white\", palette=None, rc={\"axes.linewidth\": 1})\n",
    "plt.rc(\"image\", cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load useful libraries\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 1: Load the dataset with fixed noise and fixed PSF </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available variables: ['img', 'img_nonoise', 'label', 'psf_r', 'snr', 'sigma', 'train_test']\n"
     ]
    }
   ],
   "source": [
    "# Read the data set\n",
    "dataset = \"./cs109b-project/data/data_v1.npz\"\n",
    "\n",
    "with np.load(dataset) as data:\n",
    "    print(\"Available variables:\", data.files)\n",
    "\n",
    "    image = data[\"img\"]\n",
    "    image_nonoise = data[\"img_nonoise\"]\n",
    "    label = data[\"label\"]\n",
    "    snr = data[\"snr\"]\n",
    "    sigma = data[\"sigma\"]\n",
    "    psf = data[\"psf_r\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Join Sigma and PSF with the Label data </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Singma and PSF with the label\n",
    "label = np.hstack([label, sigma.reshape(-1,1), psf.reshape(-1,1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 2: Normalize the data and split the data into Traning and Validation sets </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape images to 3D array\n",
    "image = image.reshape(image.shape[0], image.shape[1], image.shape[2], 1)\n",
    "image_nonoise = image_nonoise.reshape(image_nonoise.shape[0], image_nonoise.shape[1], image_nonoise.shape[2], 1)\n",
    "\n",
    "\n",
    "# Split into 90% train and 10% test (creates a view of the array)\n",
    "n_train = int(label.shape[0] * 0.9)\n",
    "image_train, image_val = image[:n_train], image[n_train:]\n",
    "image_nonoise_train, image_nonoise_val = image_nonoise[:n_train], image_nonoise[n_train:]\n",
    "label_train, label_val = label[:n_train], label[n_train:]\n",
    "snr_train, snr_val = snr[:n_train], snr[n_train:]\n",
    "sigma_train, sigma_val = sigma[:n_train], sigma[n_train:]\n",
    "psf_train, psf_val = psf[:n_train], psf[n_train:]\n",
    "\n",
    "\n",
    "# Zero-One Normalization of the labels\n",
    "label_min = label.min(axis=0)\n",
    "label_max = label.max(axis=0)\n",
    "label_diff = np.maximum((label_max - label_min),1e-10)\n",
    "\n",
    "label_train = (label_train - label_min)/label_diff\n",
    "label_val = (label_val - label_min)/label_diff\n",
    "\n",
    "\n",
    "# Zero-One Normalization of the no-noise images\n",
    "image_nonoise_min = image_nonoise.min()\n",
    "image_nonoise_max = image_nonoise.max()\n",
    "image_nonoise_diff = (image_nonoise_max - image_nonoise_min)\n",
    "\n",
    "image_nonoise_train = (image_nonoise_train - image_nonoise_min)/image_nonoise_diff\n",
    "image_nonoise_val = (image_nonoise_val - image_nonoise_min)/image_nonoise_diff\n",
    "\n",
    "\n",
    "# Zero-One Normalization of the noisy images\n",
    "image_min = image.min()\n",
    "image_max = image.max()\n",
    "image_diff = (image_max - image_min)\n",
    "\n",
    "image_train = (image_train - image_min)/image_diff\n",
    "image_val = (image_val - image_min)/image_diff\n",
    "\n",
    "\n",
    "# Compute Image Statistics\n",
    "stats = np.hstack([image.mean(axis=(1,2)).reshape(-1,1), image.std(axis=(1,2)).reshape(-1,1), \n",
    "                   image.min(axis=(1,2)).reshape(-1,1), image.max(axis=(1,2)).reshape(-1,1)])\n",
    "stats_train, stats_val = stats[:n_train], stats[n_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 3: Structure and Size of the Data </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape            = (200000, 64, 64, 1)\n",
      "No-noise Image Shape   = (200000, 64, 64, 1)\n",
      "Label Shape            = (200000, 7)\n",
      "SNR Shape              = (200000,)\n",
      "Sigma Shape            = (200000,)\n",
      "PSF-R Shape            = (200000,)\n",
      "Stats Shape            = (200000, 4)\n"
     ]
    }
   ],
   "source": [
    "# Structure and Size of the Data\n",
    "print(\"Image Shape            = {}\".format(image.shape))\n",
    "print(\"No-noise Image Shape   = {}\".format(image_nonoise.shape))\n",
    "print(\"Label Shape            = {}\".format(label.shape))\n",
    "print(\"SNR Shape              = {}\".format(snr.shape))\n",
    "print(\"Sigma Shape            = {}\".format(sigma.shape))\n",
    "print(\"PSF-R Shape            = {}\".format(psf.shape))\n",
    "print(\"Stats Shape            = {}\".format(stats.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 4: Create Data Pipeline </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Create Tensorflow Dataset </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensorflow Dataset\n",
    "training = tf.data.Dataset.from_tensor_slices({\n",
    "    \"Image\": image_train,\n",
    "    \"No-noise Image\": image_nonoise_train,\n",
    "    \"Labels\": label_train,\n",
    "    \"Stats\": stats_train\n",
    "})\n",
    "\n",
    "validation = tf.data.Dataset.from_tensor_slices({\n",
    "    \"Image\": image_val,\n",
    "    \"No-noise Image\": image_nonoise_val,\n",
    "    \"Labels\": label_val,\n",
    "    \"Stats\": stats_val\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Define pipeline functions to structure dataset </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_label_to_clean_image(element):\n",
    "    image = element['No-noise Image']\n",
    "    label = tf.cast(element['Labels'], tf.float32)\n",
    "    stats = tf.cast(element['Stats'], tf.float32)\n",
    "    \n",
    "    return ((label, stats), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_noisy_image_to_label(element):\n",
    "    image = element['Image']\n",
    "    label = tf.cast(element['Labels'], tf.float32)\n",
    "    stats = tf.cast(element['Stats'], tf.float32)\n",
    "    \n",
    "    return ((image, stats), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_noisy_image_to_clean_image(element):\n",
    "    image = element['Image']\n",
    "    label = tf.cast(element['Labels'], tf.float32)\n",
    "    stats = tf.cast(element['Stats'], tf.float32)\n",
    "    clean = element['No-noise Image']\n",
    "    \n",
    "    return ((image, stats), (clean, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Create dataset pipeline </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Size\n",
    "batch_size = 256\n",
    "\n",
    "\n",
    "# Data pipeline for Decoder\n",
    "tr_ds = training.map(\n",
    "    pipeline_label_to_clean_image).shuffle(1024).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_ds = validation.map(\n",
    "    pipeline_label_to_clean_image).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Data pipeline for Encoder\n",
    "tr_ds_en = training.map(\n",
    "    pipeline_noisy_image_to_label).shuffle(1024).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_ds_en = validation.map(\n",
    "    pipeline_noisy_image_to_label).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "# Data pipeline for AE\n",
    "tr_ds_AE = training.map(\n",
    "    pipeline_noisy_image_to_clean_image).shuffle(1024).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_ds_AE = validation.map(\n",
    "    pipeline_noisy_image_to_clean_image).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 5: Create Convolution Encoders and Decoder </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Declare global model parameters </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Encoder Inout Dimension\n",
    "input_shape_img = (64,64,1)\n",
    "input_shape_stats = (4,)\n",
    "\n",
    "# Dropout rate for dense layers\n",
    "dropout = 0.5\n",
    "\n",
    "# Encoder Output dimension - Decoder Input Dimension\n",
    "latent_z_dim_labels = 7\n",
    "latent_z_dim_stats = 4\n",
    "\n",
    "# Decoder latent dimension\n",
    "latent_dim = (1,1,2048)\n",
    "\n",
    "# Number of Training Epochs\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Define convolution encoder </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvEncoder(layers.Layer):\n",
    "    \"\"\"\n",
    "    Convolutional Encoder Layer Class.\n",
    "    Converts an input into a latent representation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_shape, dropout_rate=0.0, name='encoder', **kwargs):\n",
    "        \"\"\"\n",
    "        Initializes the encoder layers and saves them as local attribute.\n",
    "        \n",
    "        Input:\n",
    "        -input_dim: 3D-tuple with (rows, cols, channels) input image dimensions.\n",
    "        \n",
    "        Returns nothing.\n",
    "        \"\"\"\n",
    "        super(ConvEncoder, self).__init__(name=name, input_shape=input_shape, **kwargs)\n",
    "        \n",
    "        ## your code here\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', strides=(2,2))\n",
    "        self.lRelu1 = layers.LeakyReLU()\n",
    "        self.drop1 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        self.conv2 = layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', strides=(2,2))\n",
    "        self.lRelu2 = layers.LeakyReLU()\n",
    "        self.drop2 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        self.conv3 = layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', strides=(2,2))\n",
    "        self.lRelu3 = layers.LeakyReLU()\n",
    "        self.drop3 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        self.conv4 = layers.Conv2D(filters=256, kernel_size=(3,3), padding='same', strides=(2,2))\n",
    "        self.lRelu4 = layers.LeakyReLU()\n",
    "        self.drop4 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        self.conv5 = layers.Conv2D(filters=512, kernel_size=(3,3), padding='same', strides=(2,2))\n",
    "        self.lRelu5 = layers.LeakyReLU()\n",
    "        self.drop5 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        self.conv6 = layers.Conv2D(filters=2048, kernel_size=(3,3), padding='same', strides=(2,2))\n",
    "        self.lRelu6 = layers.LeakyReLU()\n",
    "        self.drop6 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        # end of your code here\n",
    "        \n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"\n",
    "        Runs the encoding inference for `inputs`.\n",
    "        \n",
    "        Inputs:\n",
    "        -inputs: 4D-tensor with dimension (batch_size, self.input_dim).\n",
    "        \"\"\"\n",
    "        ## your code here\n",
    "        \n",
    "        z = self.conv1(inputs)\n",
    "        z = self.lRelu1(z)\n",
    "        z = self.drop1(z)\n",
    "        \n",
    "        z = self.conv2(z)\n",
    "        z = self.lRelu2(z)\n",
    "        z = self.drop2(z)\n",
    "        \n",
    "        z = self.conv3(z)\n",
    "        z = self.lRelu3(z)\n",
    "        z = self.drop3(z)\n",
    "        \n",
    "        z = self.conv4(z)\n",
    "        z = self.lRelu4(z)\n",
    "        z = self.drop4(z)\n",
    "        \n",
    "        z = self.conv5(z)\n",
    "        z = self.lRelu5(z)\n",
    "        z = self.drop5(z)\n",
    "        \n",
    "        z = self.conv6(z)\n",
    "        z = self.lRelu6(z)\n",
    "        z = self.drop6(z)\n",
    "        \n",
    "        # end of your code here\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Define convolution decoder </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDecoder(layers.Layer):\n",
    "    \"\"\"\n",
    "    Convolutional Decoder Layer Class.\n",
    "    Converts z, the encoded digit vector, back into a readable digit.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_shape, dropout_rate=0.0, name='decoder', **kwargs):\n",
    "        \"\"\"\n",
    "        Initializes the decoder architecture and saves it as a local attribute.\n",
    "        \n",
    "        Input:\n",
    "        -input_shape: 3D-tuple with (rows, cols, channels) input representation.\n",
    "        \n",
    "        Returns nothing.\n",
    "        \"\"\"\n",
    "        super(ConvDecoder, self).__init__(name=name, input_shape=input_shape, **kwargs)\n",
    "        \n",
    "        # your code here\n",
    "        self.convT1 = layers.Conv2DTranspose(512, kernel_size=(3,3), strides=(2,2), padding='same')\n",
    "        self.lRelu1 = layers.LeakyReLU()\n",
    "        self.drop1 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        self.convT2 = layers.Conv2DTranspose(256, kernel_size=(3,3), strides=(2,2), padding='same')\n",
    "        self.lRelu2 = layers.LeakyReLU()\n",
    "        self.drop2 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        self.convT3 = layers.Conv2DTranspose(128, kernel_size=(3,3), strides=(2,2), padding='same')\n",
    "        self.lRelu3 = layers.LeakyReLU()\n",
    "        self.drop3 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        self.convT4 = layers.Conv2DTranspose(64, kernel_size=(3,3), strides=(2,2), padding='same')\n",
    "        self.lRelu4 = layers.LeakyReLU()\n",
    "        self.drop4 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        self.convT5 = layers.Conv2DTranspose(32, kernel_size=(3,3), strides=(2,2), padding='same')\n",
    "        self.lRelu5 = layers.LeakyReLU()\n",
    "        self.drop5 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        self.convT6 = layers.Conv2DTranspose(1, kernel_size=(3,3), strides=(2,2), padding='same', \n",
    "                                             activation='sigmoid')\n",
    "        # end of your code here\n",
    "        \n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"\n",
    "        Runs the encoding inference for `inputs`.\n",
    "        \n",
    "        Inputs:\n",
    "        -inputs: 4D-tensor with dimension (batch_size, self.input_dim).\n",
    "        \"\"\"\n",
    "        ## your code here\n",
    "        \n",
    "        x = self.convT1(inputs)\n",
    "        x = self.lRelu1(x)\n",
    "        x = self.drop1(x)\n",
    "        \n",
    "        x = self.convT2(x)\n",
    "        x = self.lRelu2(x)\n",
    "        x = self.drop2(x)\n",
    "        \n",
    "        x = self.convT3(x)\n",
    "        x = self.lRelu3(x)\n",
    "        x = self.drop3(x)\n",
    "        \n",
    "        x = self.convT4(x)\n",
    "        x = self.lRelu4(x)\n",
    "        x = self.drop4(x)\n",
    "        \n",
    "        x = self.convT5(x)\n",
    "        x = self.lRelu5(x)\n",
    "        x = self.drop5(x)\n",
    "        \n",
    "        x = self.convT6(x)\n",
    "        \n",
    "        # end your code here\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 5: Create Conditional Auto-encoder </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Create Label to Image Decoder </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Reverse_Decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 7)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              8192      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              2099200   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 1, 1, 2048)        0         \n",
      "_________________________________________________________________\n",
      "decoder (ConvDecoder)        (None, 64, 64, 1)         11005185  \n",
      "=================================================================\n",
      "Total params: 13,112,577\n",
      "Trainable params: 13,112,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Reverse Decoder Model\n",
    "def create_reverse_decoder():\n",
    "\n",
    "    # Create Reverse Decoder\n",
    "    input_decoder_labels = layers.Input(latent_z_dim_labels)\n",
    "    #input_decoder_stats = layers.Input(latent_z_dim_stats)\n",
    "    \n",
    "    #x = layers.concatenate([input_decoder_labels, input_decoder_stats])\n",
    "    \n",
    "    x = layers.Dense(1024)(input_decoder_labels)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "    x = layers.Dense(2048)(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "    x = layers.Reshape(latent_dim)(x)\n",
    "    recon = ConvDecoder(latent_dim)(x)\n",
    "    \n",
    "    # Decoder Model\n",
    "    #decoder = tf.keras.Model([input_decoder_labels, input_decoder_stats], recon, name='Reverse_Decoder')\n",
    "    decoder = tf.keras.Model(input_decoder_labels, recon, name='Reverse_Decoder')\n",
    "    display(decoder.summary())\n",
    "    \n",
    "    # Compile the model\n",
    "    optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "    decoder.compile(optimizer, loss=losses.BinaryCrossentropy())\n",
    "    \n",
    "    # Return reverse decoder\n",
    "    return decoder\n",
    "\n",
    "reverse_decoder = create_reverse_decoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Create Image to Label Encoder conditional on Images Statistics</b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Reverse_Encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (ConvEncoder)           (None, 1, 1, 2048)   11007232    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2052)         0           flatten[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2048)         4204544     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 2048)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 2048)         0           leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1024)         2098176     dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 1024)         0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 7)            7175        dropout_14[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 17,317,127\n",
      "Trainable params: 17,317,127\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Reverse Decoder Model\n",
    "def create_reverse_encoder():\n",
    "\n",
    "    # Create Reverse Encoder\n",
    "    input_encoder_img = layers.Input(input_shape_img)\n",
    "    input_encoder_stats = layers.Input(input_shape_stats)\n",
    "    \n",
    "    x = ConvEncoder(input_shape_img)(input_encoder_img)\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.concatenate([x, input_encoder_stats])\n",
    "    \n",
    "    x = layers.Dense(2048)(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "    x = layers.Dense(1024)(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "    latent_z = layers.Dense(latent_z_dim_labels, activation='sigmoid')(x)\n",
    "    \n",
    "    \n",
    "    # Encoder Model\n",
    "    encoder = tf.keras.Model([input_encoder_img, input_encoder_stats], latent_z, name='Reverse_Encoder')\n",
    "    display(encoder.summary())\n",
    "    \n",
    "    # Compile the model\n",
    "    optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "    encoder.compile(optimizer, loss=losses.BinaryCrossentropy())\n",
    "    \n",
    "    # Return reverse decoder\n",
    "    return encoder\n",
    "\n",
    "reverse_encoder = create_reverse_encoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Create Noisy image to Clean image and Label Auto-encoder conditional on image statistics</b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Reverse_AE\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Reverse_Encoder (Model)         (None, 7)            17317127    input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Reverse_Decoder (Model)         (None, 64, 64, 1)    13112577    Reverse_Encoder[1][0]            \n",
      "==================================================================================================\n",
      "Total params: 30,429,704\n",
      "Trainable params: 30,429,704\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_reverse_AE():\n",
    "    input_encoder_img = layers.Input(input_shape_img)\n",
    "    input_encoder_stats = layers.Input(input_shape_stats)\n",
    "    \n",
    "    labels = reverse_encoder([input_encoder_img, input_encoder_stats])\n",
    "    recons = reverse_decoder(labels)\n",
    "    \n",
    "    # Reverse AE Model\n",
    "    reverse_AE = tf.keras.Model([input_encoder_img, input_encoder_stats], [recons, labels], name='Reverse_AE')\n",
    "    display(reverse_AE.summary())\n",
    "    \n",
    "    # Compile the model\n",
    "    optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "    reverse_AE.compile(optimizer, loss=losses.BinaryCrossentropy())\n",
    "    \n",
    "    # Return reverse decoder\n",
    "    return reverse_AE\n",
    "\n",
    "reverse_AE = create_reverse_AE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 6: Training Conditional Auto-encoder on Image Dataset with fixed noise and PSF</b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Traning conditional decoder</b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632/704 [=========================>....] - ETA: 12s - loss: 0.0120"
     ]
    }
   ],
   "source": [
    "# Run the model\n",
    "try:\n",
    "    reverse_decoder.load_weights('./model/rev_de5_1')\n",
    "    print(\"Training Loss:   {:0.5f}\".format(reverse_decoder.evaluate(tr_ds)))\n",
    "    print(\"Validation Loss: {:0.5f}\".format(reverse_decoder.evaluate(val_ds)))\n",
    "    \n",
    "except:\n",
    "    history = reverse_decoder.fit(\n",
    "        tr_ds, \n",
    "        epochs=epochs, \n",
    "        verbose=1,\n",
    "        validation_data=val_ds,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
    "    )\n",
    "    \n",
    "    reverse_decoder.save_weights('./model/rev_de5_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Generating reconstructed images from labels for visual inspection </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = val_ds.take(1)\n",
    "labels, images = next(iter(test))\n",
    "pred = reverse_decoder.predict(labels)\n",
    "pred = pred.reshape(pred.shape[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(256*1, size=8)\n",
    "\n",
    "fig, ax = plt.subplots(1,8, figsize=(20,3))\n",
    "plt.suptitle(\"Generated Images\", fontsize=25)\n",
    "for j in range(8):\n",
    "    ax[j].imshow(pred[idx[j]])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,8, figsize=(20,3))\n",
    "plt.suptitle(\"Original Images\", fontsize=25)\n",
    "for j in range(8):\n",
    "    ax[j].imshow(images[idx[j]].numpy().reshape(64,64))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Traning conditional encoder</b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run the model\n",
    "try:\n",
    "    reverse_encoder.load_weights('./model/rev_en5_1')\n",
    "    print(\"Training Loss:   {:0.5f}\".format(reverse_encoder.evaluate(tr_ds_en)))\n",
    "    print(\"Validation Loss: {:0.5f}\".format(reverse_encoder.evaluate(val_ds_en)))\n",
    "    \n",
    "except:\n",
    "    history = reverse_encoder.fit(\n",
    "        tr_ds_en, \n",
    "        epochs=epochs, \n",
    "        verbose=1,\n",
    "        validation_data=val_ds_en,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
    "    )\n",
    "    \n",
    "    reverse_encoder.save_weights('./model/rev_en5_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Generating labels from noisy images for visual inspection </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = val_ds_en.take(1)\n",
    "images, labels = next(iter(test))\n",
    "pred = reverse_encoder.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "for i in idx:\n",
    "    print(\"Pred:    \", tuple(pred[i]))\n",
    "    print(\"Orignal: \", tuple(labels[i].numpy()))\n",
    "    print(\"Error:   \", tuple(pred[i]-labels[i].numpy()))\n",
    "    print(\"\\n###########################################################################################\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Variance Analysis </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = reverse_encoder.predict(val_ds_en)\n",
    "error_unscaled = (pred - label_val) * label_diff\n",
    "\n",
    "MSE = (error_unscaled**2).mean(axis=0)\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "label_var = (label_val.std(axis=0) * label_diff)**2\n",
    "\n",
    "unexplained_var = MSE/np.maximum(label_var, 1e-10)\n",
    "\n",
    "print(\"RMSE:                  {}\".format(tuple(RMSE)))\n",
    "print(\"Unexplained Variance:  {}\".format(tuple(unexplained_var)))\n",
    "print(\"Explained Variance:    {}\".format(tuple(1-unexplained_var)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Finetuning Conditional Auto-encoder </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model\n",
    "try:\n",
    "    reverse_AE.load_weights('./model/rev_AE5_1')\n",
    "    print(\"Training Loss:   {}\".format(reverse_AE.evaluate(tr_ds_AE)))\n",
    "    print(\"Validation Loss: {}\".format(reverse_AE.evaluate(val_ds_AE)))\n",
    "    \n",
    "except:\n",
    "    history = reverse_AE.fit(\n",
    "        tr_ds_AE, \n",
    "        epochs=epochs, \n",
    "        verbose=1,\n",
    "        validation_data=val_ds_AE,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
    "    )\n",
    "    \n",
    "    reverse_AE.save_weights('./model/rev_AE5_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Generating reconstructed images from labels for visual inspection </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = val_ds_AE.take(1)\n",
    "(images, stats), (clean, labels) = next(iter(test))\n",
    "pred_img, pred_lab = reverse_AE.predict([images, stats])\n",
    "pred = pred_img.reshape(pred_img.shape[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,8, figsize=(20,3))\n",
    "plt.suptitle(\"Generated Images\", fontsize=25)\n",
    "for j in range(8):\n",
    "    ax[j].imshow(pred[idx[j]])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,8, figsize=(20,3))\n",
    "plt.suptitle(\"Clean Images\", fontsize=25)\n",
    "for j in range(8):\n",
    "    ax[j].imshow(clean[idx[j]].numpy().reshape(64,64))\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1,8, figsize=(20,3))\n",
    "plt.suptitle(\"Original Noisy Images\", fontsize=25)\n",
    "for j in range(8):\n",
    "    ax[j].imshow(images[idx[j]].numpy().reshape(64,64))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Generating labels from noisy images for visual inspection </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in idx:\n",
    "    print(\"Pred:    \", tuple(pred_lab[i]))\n",
    "    print(\"Orignal: \", tuple(labels[i].numpy()))\n",
    "    print(\"Error:   \", tuple(pred_lab[i]-labels[i].numpy()))\n",
    "    print(\"\\n###########################################################################################\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Variance Analysis </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, pred = reverse_AE.predict(val_ds_en)\n",
    "error_unscaled = (pred - label_val) * label_diff\n",
    "\n",
    "MSE = (error_unscaled**2).mean(axis=0)\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "label_var = (label_val.std(axis=0) * label_diff)**2\n",
    "\n",
    "unexplained_var = MSE/np.maximum(label_var, 1e-10)\n",
    "\n",
    "print(\"RMSE:                  {}\".format(tuple(RMSE)))\n",
    "print(\"Unexplained Variance:  {}\".format(tuple(unexplained_var)))\n",
    "print(\"Explained Variance:    {}\".format(tuple(1-unexplained_var)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> End of Part 1 </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> Part 2 </div> \n",
    "\n",
    "<div style=\"border: 3px solid #800080; padding: 10px\"> \n",
    "\n",
    "## GalSim Images with variable Sigma and fixed PSF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 1: Load the dataset with variable noise and fixed PSF </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data set\n",
    "dataset = \"./cs109b-project/data/data_v2.npz\"\n",
    "\n",
    "with np.load(dataset) as data:\n",
    "    print(\"Available variables:\", data.files)\n",
    "\n",
    "    image = data[\"img\"]\n",
    "    image_nonoise = data[\"img_nonoise\"]\n",
    "    label = data[\"label\"]\n",
    "    snr = data[\"snr\"]\n",
    "    sigma = data[\"sigma\"]\n",
    "    psf = data[\"psf_r\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Join Sigma and PSF with the Label data </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Singma and PSF with the label\n",
    "label = np.hstack([label, sigma.reshape(-1,1), psf.reshape(-1,1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 2: Normalize the data and split the data into Traning and Validation sets </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape images to 3D array\n",
    "image = image.reshape(image.shape[0], image.shape[1], image.shape[2], 1)\n",
    "image_nonoise = image_nonoise.reshape(image_nonoise.shape[0], image_nonoise.shape[1], image_nonoise.shape[2], 1)\n",
    "\n",
    "\n",
    "# Split into 90% train and 10% test (creates a view of the array)\n",
    "n_train = int(label.shape[0] * 0.9)\n",
    "image_train, image_val = image[:n_train], image[n_train:]\n",
    "image_nonoise_train, image_nonoise_val = image_nonoise[:n_train], image_nonoise[n_train:]\n",
    "label_train, label_val = label[:n_train], label[n_train:]\n",
    "snr_train, snr_val = snr[:n_train], snr[n_train:]\n",
    "sigma_train, sigma_val = sigma[:n_train], sigma[n_train:]\n",
    "psf_train, psf_val = psf[:n_train], psf[n_train:]\n",
    "\n",
    "\n",
    "# Zero-One Normalization of the labels\n",
    "label_min = label.min(axis=0)\n",
    "label_max = label.max(axis=0)\n",
    "label_diff = np.maximum((label_max - label_min),1e-10)\n",
    "\n",
    "label_train = (label_train - label_min)/label_diff\n",
    "label_val = (label_val - label_min)/label_diff\n",
    "\n",
    "\n",
    "# Zero-One Normalization of the no-noise images\n",
    "image_nonoise_min = image_nonoise.min()\n",
    "image_nonoise_max = image_nonoise.max()\n",
    "image_nonoise_diff = (image_nonoise_max - image_nonoise_min)\n",
    "\n",
    "image_nonoise_train = (image_nonoise_train - image_nonoise_min)/image_nonoise_diff\n",
    "image_nonoise_val = (image_nonoise_val - image_nonoise_min)/image_nonoise_diff\n",
    "\n",
    "\n",
    "# Zero-One Normalization of the noisy images\n",
    "image_min = image.min()\n",
    "image_max = image.max()\n",
    "image_diff = (image_max - image_min)\n",
    "\n",
    "image_train = (image_train - image_min)/image_diff\n",
    "image_val = (image_val - image_min)/image_diff\n",
    "\n",
    "\n",
    "# Compute Image Statistics\n",
    "stats = np.hstack([image.mean(axis=(1,2)).reshape(-1,1), image.std(axis=(1,2)).reshape(-1,1), \n",
    "                   image.min(axis=(1,2)).reshape(-1,1), image.max(axis=(1,2)).reshape(-1,1)])\n",
    "stats_train, stats_val = stats[:n_train], stats[n_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 3: Structure and Size of the Data </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure and Size of the Data\n",
    "print(\"Image Shape            = {}\".format(image.shape))\n",
    "print(\"No-noise Image Shape   = {}\".format(image_nonoise.shape))\n",
    "print(\"Label Shape            = {}\".format(label.shape))\n",
    "print(\"SNR Shape              = {}\".format(snr.shape))\n",
    "print(\"Sigma Shape            = {}\".format(sigma.shape))\n",
    "print(\"PSF-R Shape            = {}\".format(psf.shape))\n",
    "print(\"Stats Shape            = {}\".format(stats.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 4: Create Data Pipeline </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Create Tensorflow Dataset </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensorflow Dataset\n",
    "training = tf.data.Dataset.from_tensor_slices({\n",
    "    \"Image\": image_train,\n",
    "    \"No-noise Image\": image_nonoise_train,\n",
    "    \"Labels\": label_train,\n",
    "    \"Stats\": stats_train\n",
    "})\n",
    "\n",
    "validation = tf.data.Dataset.from_tensor_slices({\n",
    "    \"Image\": image_val,\n",
    "    \"No-noise Image\": image_nonoise_val,\n",
    "    \"Labels\": label_val,\n",
    "    \"Stats\": stats_val\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Define pipeline functions to structure dataset </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_label_to_clean_image(element):\n",
    "    image = element['No-noise Image']\n",
    "    label = tf.cast(element['Labels'], tf.float32)\n",
    "    stats = tf.cast(element['Stats'], tf.float32)\n",
    "    \n",
    "    return ((label, stats), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_noisy_image_to_label(element):\n",
    "    image = element['Image']\n",
    "    label = tf.cast(element['Labels'], tf.float32)\n",
    "    stats = tf.cast(element['Stats'], tf.float32)\n",
    "    \n",
    "    return ((image, stats), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_noisy_image_to_clean_image(element):\n",
    "    image = element['Image']\n",
    "    label = tf.cast(element['Labels'], tf.float32)\n",
    "    stats = tf.cast(element['Stats'], tf.float32)\n",
    "    clean = element['No-noise Image']\n",
    "    \n",
    "    return ((image, stats), (clean, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Create dataset pipeline </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Size\n",
    "batch_size = 256\n",
    "\n",
    "\n",
    "# Data pipeline for Decoder\n",
    "tr_ds = training.map(\n",
    "    pipeline_label_to_clean_image).shuffle(1024).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_ds = validation.map(\n",
    "    pipeline_label_to_clean_image).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Data pipeline for Encoder\n",
    "tr_ds_en = training.map(\n",
    "    pipeline_noisy_image_to_label).shuffle(1024).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_ds_en = validation.map(\n",
    "    pipeline_noisy_image_to_label).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "# Data pipeline for AE\n",
    "tr_ds_AE = training.map(\n",
    "    pipeline_noisy_image_to_clean_image).shuffle(1024).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_ds_AE = validation.map(\n",
    "    pipeline_noisy_image_to_clean_image).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 6: Training Conditional Auto-encoder on Image Dataset with variable noise and fixed PSF</b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Traning conditional decoder</b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run the model\n",
    "try:\n",
    "    reverse_decoder.load_weights('./model/rev_de5_2')\n",
    "    print(\"Training Loss:   {:0.5f}\".format(reverse_decoder.evaluate(tr_ds)))\n",
    "    print(\"Validation Loss: {:0.5f}\".format(reverse_decoder.evaluate(val_ds)))\n",
    "    \n",
    "except:\n",
    "    history = reverse_decoder.fit(\n",
    "        tr_ds, \n",
    "        epochs=epochs, \n",
    "        verbose=1,\n",
    "        validation_data=val_ds,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
    "    )\n",
    "    \n",
    "    reverse_decoder.save_weights('./model/rev_de5_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Generating reconstructed images from labels for visual inspection </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = val_ds.take(1)\n",
    "labels, images = next(iter(test))\n",
    "pred = reverse_decoder.predict(labels)\n",
    "pred = pred.reshape(pred.shape[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(256*1, size=8)\n",
    "\n",
    "fig, ax = plt.subplots(1,8, figsize=(20,3))\n",
    "plt.suptitle(\"Generated Images\", fontsize=25)\n",
    "for j in range(8):\n",
    "    ax[j].imshow(pred[idx[j]])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,8, figsize=(20,3))\n",
    "plt.suptitle(\"Original Images\", fontsize=25)\n",
    "for j in range(8):\n",
    "    ax[j].imshow(images[idx[j]].numpy().reshape(64,64))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Traning conditional encoder</b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run the model\n",
    "try:\n",
    "    reverse_encoder.load_weights('./model/rev_en5_2')\n",
    "    print(\"Training Loss:   {:0.5f}\".format(reverse_encoder.evaluate(tr_ds_en)))\n",
    "    print(\"Validation Loss: {:0.5f}\".format(reverse_encoder.evaluate(val_ds_en)))\n",
    "    \n",
    "except:\n",
    "    history = reverse_encoder.fit(\n",
    "        tr_ds_en, \n",
    "        epochs=epochs, \n",
    "        verbose=1,\n",
    "        validation_data=val_ds_en,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
    "    )\n",
    "    \n",
    "    reverse_encoder.save_weights('./model/rev_en5_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Generating labels from noisy images for visual inspection </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = val_ds_en.take(1)\n",
    "images, labels = next(iter(test))\n",
    "pred = reverse_encoder.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "for i in idx:\n",
    "    print(\"Pred:    \", tuple(pred[i]))\n",
    "    print(\"Orignal: \", tuple(labels[i].numpy()))\n",
    "    print(\"Error:   \", tuple(pred[i]-labels[i].numpy()))\n",
    "    print(\"\\n###########################################################################################\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Variance Analysis </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = reverse_encoder.predict(val_ds_en)\n",
    "error_unscaled = (pred - label_val) * label_diff\n",
    "\n",
    "MSE = (error_unscaled**2).mean(axis=0)\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "label_var = (label_val.std(axis=0) * label_diff)**2\n",
    "\n",
    "unexplained_var = MSE/np.maximum(label_var, 1e-10)\n",
    "\n",
    "print(\"RMSE:                  {}\".format(tuple(RMSE)))\n",
    "print(\"Unexplained Variance:  {}\".format(tuple(unexplained_var)))\n",
    "print(\"Explained Variance:    {}\".format(tuple(1-unexplained_var)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Finetuning Conditional Auto-encoder </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run the model\n",
    "try:\n",
    "    reverse_AE.load_weights('./model/rev_AE5_2')\n",
    "    print(\"Training Loss:   {}\".format(reverse_AE.evaluate(tr_ds_AE)))\n",
    "    print(\"Validation Loss: {}\".format(reverse_AE.evaluate(val_ds_AE)))\n",
    "    \n",
    "except:\n",
    "    history = reverse_AE.fit(\n",
    "        tr_ds_AE, \n",
    "        epochs=epochs, \n",
    "        verbose=1,\n",
    "        validation_data=val_ds_AE,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
    "    )\n",
    "    \n",
    "    reverse_AE.save_weights('./model/rev_AE5_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Generating reconstructed images from labels for visual inspection </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = val_ds_AE.take(1)\n",
    "(images, stats), (clean, labels) = next(iter(test))\n",
    "pred_img, pred_lab = reverse_AE.predict([images, stats])\n",
    "pred = pred_img.reshape(pred_img.shape[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,8, figsize=(20,3))\n",
    "plt.suptitle(\"Generated Images\", fontsize=25)\n",
    "for j in range(8):\n",
    "    ax[j].imshow(pred[idx[j]])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,8, figsize=(20,3))\n",
    "plt.suptitle(\"Clean Images\", fontsize=25)\n",
    "for j in range(8):\n",
    "    ax[j].imshow(clean[idx[j]].numpy().reshape(64,64))\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1,8, figsize=(20,3))\n",
    "plt.suptitle(\"Original Noisy Images\", fontsize=25)\n",
    "for j in range(8):\n",
    "    ax[j].imshow(images[idx[j]].numpy().reshape(64,64))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Generating labels from noisy images for visual inspection </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in idx:\n",
    "    print(\"Pred:    \", tuple(pred_lab[i]))\n",
    "    print(\"Orignal: \", tuple(labels[i].numpy()))\n",
    "    print(\"Error:   \", tuple(pred_lab[i]-labels[i].numpy()))\n",
    "    print(\"\\n###########################################################################################\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Variance Analysis </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, pred = reverse_AE.predict(val_ds_en)\n",
    "error_unscaled = (pred - label_val) * label_diff\n",
    "\n",
    "MSE = (error_unscaled**2).mean(axis=0)\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "label_var = (label_val.std(axis=0) * label_diff)**2\n",
    "\n",
    "unexplained_var = MSE/np.maximum(label_var, 1e-10)\n",
    "\n",
    "print(\"RMSE:                  {}\".format(tuple(RMSE)))\n",
    "print(\"Unexplained Variance:  {}\".format(tuple(unexplained_var)))\n",
    "print(\"Explained Variance:    {}\".format(tuple(1-unexplained_var)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> End of Part 2 </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> Part 3 </div> \n",
    "\n",
    "<div style=\"border: 3px solid #800080; padding: 10px\"> \n",
    "\n",
    "## GalSim Images with variable Sigma and variable PSF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 1: Load the dataset with variable noise and variable PSF </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data set\n",
    "dataset = \"./cs109b-project/data/data_v3.npz\"\n",
    "\n",
    "with np.load(dataset) as data:\n",
    "    print(\"Available variables:\", data.files)\n",
    "\n",
    "    image = data[\"img\"]\n",
    "    image_nonoise = data[\"img_nonoise\"]\n",
    "    label = data[\"label\"]\n",
    "    snr = data[\"snr\"]\n",
    "    sigma = data[\"sigma\"]\n",
    "    psf = data[\"psf_r\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Join Sigma and PSF with the Label data </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Singma and PSF with the label\n",
    "label = np.hstack([label, sigma.reshape(-1,1), psf.reshape(-1,1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 2: Normalize the data and split the data into Traning and Validation sets </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape images to 3D array\n",
    "image = image.reshape(image.shape[0], image.shape[1], image.shape[2], 1)\n",
    "image_nonoise = image_nonoise.reshape(image_nonoise.shape[0], image_nonoise.shape[1], image_nonoise.shape[2], 1)\n",
    "\n",
    "\n",
    "# Split into 90% train and 10% test (creates a view of the array)\n",
    "n_train = int(label.shape[0] * 0.9)\n",
    "image_train, image_val = image[:n_train], image[n_train:]\n",
    "image_nonoise_train, image_nonoise_val = image_nonoise[:n_train], image_nonoise[n_train:]\n",
    "label_train, label_val = label[:n_train], label[n_train:]\n",
    "snr_train, snr_val = snr[:n_train], snr[n_train:]\n",
    "sigma_train, sigma_val = sigma[:n_train], sigma[n_train:]\n",
    "psf_train, psf_val = psf[:n_train], psf[n_train:]\n",
    "\n",
    "\n",
    "# Zero-One Normalization of the labels\n",
    "label_min = label.min(axis=0)\n",
    "label_max = label.max(axis=0)\n",
    "label_diff = np.maximum((label_max - label_min),1e-10)\n",
    "\n",
    "label_train = (label_train - label_min)/label_diff\n",
    "label_val = (label_val - label_min)/label_diff\n",
    "\n",
    "\n",
    "# Zero-One Normalization of the no-noise images\n",
    "image_nonoise_min = image_nonoise.min()\n",
    "image_nonoise_max = image_nonoise.max()\n",
    "image_nonoise_diff = (image_nonoise_max - image_nonoise_min)\n",
    "\n",
    "image_nonoise_train = (image_nonoise_train - image_nonoise_min)/image_nonoise_diff\n",
    "image_nonoise_val = (image_nonoise_val - image_nonoise_min)/image_nonoise_diff\n",
    "\n",
    "\n",
    "# Zero-One Normalization of the noisy images\n",
    "image_min = image.min()\n",
    "image_max = image.max()\n",
    "image_diff = (image_max - image_min)\n",
    "\n",
    "image_train = (image_train - image_min)/image_diff\n",
    "image_val = (image_val - image_min)/image_diff\n",
    "\n",
    "\n",
    "# Compute Image Statistics\n",
    "stats = np.hstack([image.mean(axis=(1,2)).reshape(-1,1), image.std(axis=(1,2)).reshape(-1,1), \n",
    "                   image.min(axis=(1,2)).reshape(-1,1), image.max(axis=(1,2)).reshape(-1,1)])\n",
    "stats_train, stats_val = stats[:n_train], stats[n_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 3: Structure and Size of the Data </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure and Size of the Data\n",
    "print(\"Image Shape            = {}\".format(image.shape))\n",
    "print(\"No-noise Image Shape   = {}\".format(image_nonoise.shape))\n",
    "print(\"Label Shape            = {}\".format(label.shape))\n",
    "print(\"SNR Shape              = {}\".format(snr.shape))\n",
    "print(\"Sigma Shape            = {}\".format(sigma.shape))\n",
    "print(\"PSF-R Shape            = {}\".format(psf.shape))\n",
    "print(\"Stats Shape            = {}\".format(stats.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 4: Create Data Pipeline </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Create Tensorflow Dataset </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensorflow Dataset\n",
    "training = tf.data.Dataset.from_tensor_slices({\n",
    "    \"Image\": image_train,\n",
    "    \"No-noise Image\": image_nonoise_train,\n",
    "    \"Labels\": label_train,\n",
    "    \"Stats\": stats_train\n",
    "})\n",
    "\n",
    "validation = tf.data.Dataset.from_tensor_slices({\n",
    "    \"Image\": image_val,\n",
    "    \"No-noise Image\": image_nonoise_val,\n",
    "    \"Labels\": label_val,\n",
    "    \"Stats\": stats_val\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Define pipeline functions to structure dataset </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_label_to_clean_image(element):\n",
    "    image = element['No-noise Image']\n",
    "    label = tf.cast(element['Labels'], tf.float32)\n",
    "    stats = tf.cast(element['Stats'], tf.float32)\n",
    "    \n",
    "    return ((label, stats), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_noisy_image_to_label(element):\n",
    "    image = element['Image']\n",
    "    label = tf.cast(element['Labels'], tf.float32)\n",
    "    stats = tf.cast(element['Stats'], tf.float32)\n",
    "    \n",
    "    return ((image, stats), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_noisy_image_to_clean_image(element):\n",
    "    image = element['Image']\n",
    "    label = tf.cast(element['Labels'], tf.float32)\n",
    "    stats = tf.cast(element['Stats'], tf.float32)\n",
    "    clean = element['No-noise Image']\n",
    "    \n",
    "    return ((image, stats), (clean, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Create dataset pipeline </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Size\n",
    "batch_size = 256\n",
    "\n",
    "\n",
    "# Data pipeline for Decoder\n",
    "tr_ds = training.map(\n",
    "    pipeline_label_to_clean_image).shuffle(1024).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_ds = validation.map(\n",
    "    pipeline_label_to_clean_image).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Data pipeline for Encoder\n",
    "tr_ds_en = training.map(\n",
    "    pipeline_noisy_image_to_label).shuffle(1024).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_ds_en = validation.map(\n",
    "    pipeline_noisy_image_to_label).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "# Data pipeline for AE\n",
    "tr_ds_AE = training.map(\n",
    "    pipeline_noisy_image_to_clean_image).shuffle(1024).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_ds_AE = validation.map(\n",
    "    pipeline_noisy_image_to_clean_image).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 6: Training Conditional Auto-encoder on Image Dataset with variable noise and PSF</b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Traning conditional decoder</b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run the model\n",
    "try:\n",
    "    reverse_decoder.load_weights('./model/rev_de5_3')\n",
    "    print(\"Training Loss:   {:0.5f}\".format(reverse_decoder.evaluate(tr_ds)))\n",
    "    print(\"Validation Loss: {:0.5f}\".format(reverse_decoder.evaluate(val_ds)))\n",
    "    \n",
    "except:\n",
    "    history = reverse_decoder.fit(\n",
    "        tr_ds, \n",
    "        epochs=epochs, \n",
    "        verbose=1,\n",
    "        validation_data=val_ds,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
    "    )\n",
    "    \n",
    "    reverse_decoder.save_weights('./model/rev_de5_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Generating reconstructed images from labels for visual inspection </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = val_ds.take(1)\n",
    "labels, images = next(iter(test))\n",
    "pred = reverse_decoder.predict(labels)\n",
    "pred = pred.reshape(pred.shape[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(256*1, size=8)\n",
    "\n",
    "fig, ax = plt.subplots(1,8, figsize=(20,3))\n",
    "plt.suptitle(\"Generated Images\", fontsize=25)\n",
    "for j in range(8):\n",
    "    ax[j].imshow(pred[idx[j]])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,8, figsize=(20,3))\n",
    "plt.suptitle(\"Original Images\", fontsize=25)\n",
    "for j in range(8):\n",
    "    ax[j].imshow(images[idx[j]].numpy().reshape(64,64))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Traning conditional encoder</b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run the model\n",
    "try:\n",
    "    reverse_encoder.load_weights('./model/rev_en5_3')\n",
    "    print(\"Training Loss:   {:0.5f}\".format(reverse_encoder.evaluate(tr_ds_en)))\n",
    "    print(\"Validation Loss: {:0.5f}\".format(reverse_encoder.evaluate(val_ds_en)))\n",
    "    \n",
    "except:\n",
    "    history = reverse_encoder.fit(\n",
    "        tr_ds_en, \n",
    "        epochs=epochs, \n",
    "        verbose=1,\n",
    "        validation_data=val_ds_en,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
    "    )\n",
    "    \n",
    "    reverse_encoder.save_weights('./model/rev_en5_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Generating labels from noisy images for visual inspection </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = val_ds_en.take(1)\n",
    "images, labels = next(iter(test))\n",
    "pred = reverse_encoder.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "for i in idx:\n",
    "    print(\"Pred:    \", tuple(pred[i]))\n",
    "    print(\"Orignal: \", tuple(labels[i].numpy()))\n",
    "    print(\"Error:   \", tuple(pred[i]-labels[i].numpy()))\n",
    "    print(\"\\n###########################################################################################\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Variance Analysis </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = reverse_encoder.predict(val_ds_en)\n",
    "error_unscaled = (pred - label_val) * label_diff\n",
    "\n",
    "MSE = (error_unscaled**2).mean(axis=0)\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "label_var = (label_val.std(axis=0) * label_diff)**2\n",
    "\n",
    "unexplained_var = MSE/np.maximum(label_var, 1e-10)\n",
    "\n",
    "print(\"RMSE:                  {}\".format(tuple(RMSE)))\n",
    "print(\"Unexplained Variance:  {}\".format(tuple(unexplained_var)))\n",
    "print(\"Explained Variance:    {}\".format(tuple(1-unexplained_var)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Finetuning Conditional Auto-encoder </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run the model\n",
    "try:\n",
    "    reverse_AE.load_weights('./model/rev_AE5_3')\n",
    "    print(\"Training Loss:   {}\".format(reverse_AE.evaluate(tr_ds_AE)))\n",
    "    print(\"Validation Loss: {}\".format(reverse_AE.evaluate(val_ds_AE)))\n",
    "    \n",
    "except:\n",
    "    history = reverse_AE.fit(\n",
    "        tr_ds_AE, \n",
    "        epochs=epochs, \n",
    "        verbose=1,\n",
    "        validation_data=val_ds_AE,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
    "    )\n",
    "    \n",
    "    reverse_AE.save_weights('./model/rev_AE5_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Generating reconstructed images from labels for visual inspection </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = val_ds_AE.take(1)\n",
    "(images, stats), (clean, labels) = next(iter(test))\n",
    "pred_img, pred_lab = reverse_AE.predict([images, stats])\n",
    "pred = pred_img.reshape(pred_img.shape[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,8, figsize=(20,3))\n",
    "plt.suptitle(\"Generated Images\", fontsize=25)\n",
    "for j in range(8):\n",
    "    ax[j].imshow(pred[idx[j]])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,8, figsize=(20,3))\n",
    "plt.suptitle(\"Clean Images\", fontsize=25)\n",
    "for j in range(8):\n",
    "    ax[j].imshow(clean[idx[j]].numpy().reshape(64,64))\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1,8, figsize=(20,3))\n",
    "plt.suptitle(\"Original Noisy Images\", fontsize=25)\n",
    "for j in range(8):\n",
    "    ax[j].imshow(images[idx[j]].numpy().reshape(64,64))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Generating labels from noisy images for visual inspection </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in idx:\n",
    "    print(\"Pred:    \", tuple(pred_lab[i]))\n",
    "    print(\"Orignal: \", tuple(labels[i].numpy()))\n",
    "    print(\"Error:   \", tuple(pred_lab[i]-labels[i].numpy()))\n",
    "    print(\"\\n###########################################################################################\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Variance Analysis </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_, pred = reverse_AE.predict(val_ds_en)\n",
    "error_unscaled = (pred - label_val) * label_diff\n",
    "\n",
    "MSE = (error_unscaled**2).mean(axis=0)\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "label_var = (label_val.std(axis=0) * label_diff)**2\n",
    "\n",
    "unexplained_var = MSE/np.maximum(label_var, 1e-10)\n",
    "\n",
    "print(\"RMSE:                  {}\".format(tuple(RMSE)))\n",
    "print(\"Unexplained Variance:  {}\".format(tuple(unexplained_var)))\n",
    "print(\"Explained Variance:    {}\".format(tuple(1-unexplained_var)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> End of Part 3 </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> Summary </div> \n",
    "\n",
    "<div style=\"border: 3px solid #800080; padding: 10px\"> \n",
    "    \n",
    "### ***Shape and Brightness of a Galaxy***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\">  End Of Project\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

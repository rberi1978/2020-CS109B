{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109B Data Science 2: Advanced Topics in Data Science \n",
    "\n",
    "##  Project F: Measuring the Shape and Brightness of Galaxies with Neural Networks\n",
    "\n",
    "### Group 75: Dmitry Vukolov, Ning Xu, Rohit Beri, Sunil Chomal\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Spring 2020**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Mark Glickman and Chris Tanner<br/>\n",
    "**Project Advisors**: Douglas Finkbeiner and Jun Yin<br/>\n",
    "\n",
    "\n",
    "<hr style=\"height:2pt\">\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THIS CELL\n",
    "import requests\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "styles = requests.get(\n",
    "    \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\"\n",
    ").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> Outline </div> \n",
    "\n",
    "1. Overview\n",
    "2. Loading the Data\n",
    "3. Structure and Size of the Data\n",
    "4. Basic Statistics of the Data \n",
    "5. Visualization of the Image Data \n",
    "6. Distributions of the Labels and Numerical Attributes \n",
    "7. Parametric Image Generation\n",
    "8. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> Overview </div> \n",
    "\n",
    "<div style=\"border: 3px solid #800080; padding: 10px\"> \n",
    "\n",
    "## Creating Galaxy images using GalSim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> Part 0 </div> \n",
    "\n",
    "<div style=\"border: 3px solid #800080; padding: 10px\"> \n",
    "\n",
    "## Load Libraries and Create Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 1: Load the essential libraries </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Load Standard Libraries </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load useful libraries\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Import h5py for reading h5 files\n",
    "import h5py\n",
    "\n",
    "# Load galsim for data generation\n",
    "import galsim\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Tweak plot resolution and styling\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "sns.set(style=\"white\", palette=None, rc={\"axes.linewidth\": 1})\n",
    "plt.rc(\"image\", cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Load Machine Learning Libraries </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load useful functions from scikit-lear\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 2: Create Helper Functions </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Function to Load Data and Divide data into Training and Validation Set </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(set=1, test=False):\n",
    "    # Path for the Traning and Validation Data\n",
    "    dataPath = [\"./cs109b-project/data/data_v1.npz\", \n",
    "                \"./cs109b-project/data/data_v2.npz\", \n",
    "                \"./cs109b-project/data/data_v3.npz\",\n",
    "                \"./cs109b-project/data/snr30.npz\",\n",
    "                \"./cs109b-project/data/snr60.npz\"\n",
    "               ]\n",
    "    \n",
    "    # Path for PSF image data\n",
    "    psfPath = [\"./cs109b-project/data/data_v1_psf.npy\", \n",
    "               \"./cs109b-project/data/data_v2_psf.npy\", \n",
    "               \"./cs109b-project/data/data_v3_psf.npy\"]\n",
    "    \n",
    "    # Load dataset\n",
    "    with np.load(dataPath[set-1]) as data:\n",
    "        print(\"\\nAvailable variables:\")\n",
    "        \n",
    "        for file in data.files:\n",
    "            print(\"    {}\".format(file))\n",
    "\n",
    "        image = data[\"img\"]\n",
    "        image_nonoise = data[\"img_nonoise\"]\n",
    "        label = data[\"label\"]\n",
    "        snr = data[\"snr\"]\n",
    "        sigma = data[\"sigma\"]\n",
    "        psf = data[\"psf_r\"]\n",
    "        \n",
    "        # Load PSF Images\n",
    "        if test:\n",
    "            print(\"    {}\".format(\"psf_image\"))\n",
    "            psf_img = data[\"psf_img\"]\n",
    "    \n",
    "    # PSF Images were saved in seperate files\n",
    "    if not test:\n",
    "        # Load PSF Images\n",
    "        print(\"    {}\".format(\"psf_image\"))\n",
    "        psf_img = np.load(psfPath[set-1])\n",
    "    \n",
    "    # Compute Image Statistics (StdDev & Mean of the pixel values of every image)\n",
    "    stats = image.std(axis=(1,2))\n",
    "    mean = image.mean(axis=(1,2))\n",
    "    \n",
    "    # Structure and Size of the Data\n",
    "    print(\"\\nImage Shape            = {}\".format(image.shape))\n",
    "    print(\"No-noise Image Shape   = {}\".format(image_nonoise.shape))\n",
    "    print(\"Label Shape            = {}\".format(label.shape))\n",
    "    print(\"SNR Shape              = {}\".format(snr.shape))\n",
    "    print(\"Sigma Shape            = {}\".format(sigma.shape))\n",
    "    print(\"PSF-R Shape            = {}\".format(psf.shape))\n",
    "    print(\"Pixel Std-dev Shape    = {}\".format(stats.shape))\n",
    "    print(\"Pixel Mean Shape       = {}\".format(mean.shape))\n",
    "    print(\"PSF Image Shape        = {}\".format(psf_img.shape))\n",
    "    \n",
    "    if not test:\n",
    "        # 90% of the data to be kept for training\n",
    "        n_train = int(snr.shape[0] * 0.9)\n",
    "\n",
    "        # Number of Training and Validation Points\n",
    "        print(\"\\nNumber of Training Points:    {}\".format(n_train))\n",
    "        print(\"Number of Validation Points:  {}\\n\".format(snr.shape[0] - n_train))\n",
    "    \n",
    "        # Divide PSF Images into training and validation depending on dataset\n",
    "        # Dataset 1 & 2 have fixed PSF and hence only one PSF image\n",
    "        if set==3:\n",
    "            psf_img_tr, psf_img_val = psf_img[:n_train], psf_img[n_train:]\n",
    "        else:\n",
    "            psf_img_tr, psf_img_val = psf_img, psf_img\n",
    "    \n",
    "        # Return Training and Validation Datasets\n",
    "        return (image[:n_train], image[n_train:],\n",
    "                image_nonoise[:n_train], image_nonoise[n_train:],\n",
    "                label[:n_train], label[n_train:],\n",
    "                psf[:n_train], psf[n_train:],\n",
    "                snr[:n_train], snr[n_train:],\n",
    "                sigma[:n_train], sigma[n_train:],\n",
    "                psf_img_tr, psf_img_val,\n",
    "                stats[:n_train], stats[n_train:],\n",
    "                mean[:n_train], mean[n_train:]\n",
    "               )\n",
    "    \n",
    "    else:\n",
    "        return (image,\n",
    "                image_nonoise,\n",
    "                label,\n",
    "                psf,\n",
    "                snr,\n",
    "                sigma,\n",
    "                psf_img,\n",
    "                stats,\n",
    "                mean\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Function to Normalize and Un-normalize Labels </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to scale labels\n",
    "def norm_label(label_train, label_val=None, scaler=None):\n",
    "    if not scaler:\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        label_train = scaler.fit_transform(label_train)\n",
    "        label_val = scaler.transform(label_val)\n",
    "        return label_train, label_val, scaler\n",
    "    \n",
    "    else:\n",
    "        return scaler.transform(label_train)\n",
    "\n",
    "\n",
    "# Function to unscale labels\n",
    "def unnorm_label(label, scaler):\n",
    "    label = scaler.inverse_transform(label)\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Function to Normalize Images without noise and reshape into 3D </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to scale images\n",
    "def norm_image(image_train, image_val=None, test=False):\n",
    "    min_pixel = image_train.min(axis=(1,2))[:,np.newaxis,np.newaxis]\n",
    "    max_pixel = image_train.max(axis=(1,2))[:,np.newaxis,np.newaxis]\n",
    "    diff = max_pixel - min_pixel\n",
    "    image_train = ((image_train - min_pixel)/diff)[:,:,:,np.newaxis]\n",
    "    \n",
    "    if not test:\n",
    "        min_pixel = image_val.min(axis=(1,2))[:,np.newaxis,np.newaxis]\n",
    "        max_pixel = image_val.max(axis=(1,2))[:,np.newaxis,np.newaxis]\n",
    "        diff = max_pixel - min_pixel\n",
    "        image_val = ((image_val - min_pixel)/diff)[:,:,:,np.newaxis]\n",
    "        return image_train, image_val\n",
    "    \n",
    "    else:\n",
    "        return image_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Function to create Tensorflow Dataset </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(set=1, test=False):\n",
    "    if not test:\n",
    "        # Number of elements in Training and Validation set\n",
    "        n_train = sigma_train.shape[0]\n",
    "        n_val = sigma_val.shape[0]\n",
    "\n",
    "        # PSF Image handling\n",
    "        if set!=3:\n",
    "            psf_img_tr = np.array(list(psf_img_train)*n_train)\n",
    "            psf_img_v = np.array(list(psf_img_train)*n_val)\n",
    "        else:\n",
    "            psf_img_tr = psf_img_train\n",
    "            psf_img_v = psf_img_val\n",
    "\n",
    "        # Reshape the Parameter\n",
    "        stats_t,  stats_v = (stats_train.reshape(-1,1), stats_val.reshape(-1,1))\n",
    "        mean_t,  mean_v = (mean_train.reshape(-1,1), mean_val.reshape(-1,1))\n",
    "\n",
    "        # Create Training Dataset    \n",
    "        training = tf.data.Dataset.from_tensor_slices({\n",
    "            \"Image\": image_train,\n",
    "            \"No-noise Image\": image_nonoise_train,\n",
    "            \"PSF_img\": psf_img_tr,\n",
    "            \"Labels\": label_train,\n",
    "            \"Variance\": stats_train[:, np.newaxis, np.newaxis]**2,\n",
    "            \"Sigma\": sigma_train[:, np.newaxis, np.newaxis],\n",
    "            \"Stats\": np.hstack([\n",
    "                stats_t,\n",
    "                mean_t\n",
    "            ])\n",
    "        })\n",
    "\n",
    "        # Create Validation Dataset\n",
    "        validation = tf.data.Dataset.from_tensor_slices({\n",
    "            \"Image\": image_val,\n",
    "            \"No-noise Image\": image_nonoise_val,\n",
    "            \"PSF_img\": psf_img_v,\n",
    "            \"Labels\": label_val,\n",
    "            \"Variance\": stats_val[:, np.newaxis, np.newaxis]**2,\n",
    "            \"Sigma\": sigma_val[:, np.newaxis, np.newaxis],\n",
    "            \"Stats\": np.hstack([\n",
    "                stats_v,\n",
    "                mean_v\n",
    "            ])\n",
    "        })\n",
    "\n",
    "        return training, validation\n",
    "    \n",
    "    else:\n",
    "        n_test = sigma_test.shape[0]\n",
    "        psf_img_te = np.array(list(psf_img_test)*n_test)\n",
    "        stats_t = stats_test.reshape(-1,1)\n",
    "        mean_t = mean_test.reshape(-1,1)\n",
    "        \n",
    "        \n",
    "        # Create testing Dataset    \n",
    "        testing = tf.data.Dataset.from_tensor_slices({\n",
    "            \"Image\": image_test,\n",
    "            \"No-noise Image\": image_nonoise_test,\n",
    "            \"PSF_img\": psf_img_te,\n",
    "            \"Labels\": label_test,\n",
    "            \"Variance\": stats_test[:, np.newaxis, np.newaxis]**2,\n",
    "            \"Sigma\": sigma_test[:, np.newaxis, np.newaxis],\n",
    "            \"Stats\": np.hstack([\n",
    "                stats_t,\n",
    "                mean_t\n",
    "            ])\n",
    "        })\n",
    "        \n",
    "        return testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Define pipeline functions to structure dataset </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_noisy_image_to_clean_image(element):\n",
    "    image = element['Image']\n",
    "    psf = element['PSF_img']\n",
    "    sigma = element['Sigma']\n",
    "    var = element['Variance']\n",
    "    stats = element['Stats']\n",
    "    \n",
    "    # Preprocessing of Images\n",
    "    img_sig = (image/sigma)\n",
    "    img_sig_sq = (image**2/(1.41* sigma**2))\n",
    "    img_var = (image/var)\n",
    "    img_var_sq = (image/(var**2 * sigma))\n",
    "    psf_sq = psf**2\n",
    "    \n",
    "    clean = element['No-noise Image']\n",
    "    label = tf.cast(element['Labels'], tf.float32)\n",
    "    \n",
    "    # Seven channel image\n",
    "    img = tf.stack([\n",
    "        image,\n",
    "        img_sig,\n",
    "        img_sig_sq,\n",
    "        img_var,\n",
    "        img_var_sq,\n",
    "        psf,\n",
    "        psf_sq],\n",
    "        axis = -1)\n",
    "    \n",
    "    return ((img, stats), (clean, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Function defining convolution encoder layer</b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvEncoder(layers.Layer):\n",
    "    \"\"\"\n",
    "    Convolutional Encoder Layer Class.\n",
    "    Converts an input into a latent representation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_shape, dropout_rate=0.0, name='encoder', **kwargs):\n",
    "        \"\"\"\n",
    "        Initializes the encoder layers and saves them as local attribute.\n",
    "        \n",
    "        Input:\n",
    "        -input_dim: 3D-tuple with (rows, cols, channels) input image dimensions.\n",
    "        \n",
    "        Returns nothing.\n",
    "        \"\"\"\n",
    "        super(ConvEncoder, self).__init__(name=name, input_shape=input_shape, **kwargs)\n",
    "        \n",
    "        self.conv1 = layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', strides=(2,2))\n",
    "        self.lRelu1 = layers.LeakyReLU()\n",
    "        self.drop1 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        self.conv2 = layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', strides=(2,2))\n",
    "        self.lRelu2 = layers.LeakyReLU()\n",
    "        self.drop2 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        self.conv3 = layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', strides=(2,2))\n",
    "        self.lRelu3 = layers.LeakyReLU()\n",
    "        self.drop3 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        self.conv4 = layers.Conv2D(filters=256, kernel_size=(3,3), padding='same', strides=(2,2))\n",
    "        self.lRelu4 = layers.LeakyReLU()\n",
    "        self.drop4 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        self.conv5 = layers.Conv2D(filters=512, kernel_size=(3,3), padding='same', strides=(2,2))\n",
    "        self.lRelu5 = layers.LeakyReLU()\n",
    "        self.drop5 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        self.conv6 = layers.Conv2D(filters=2048, kernel_size=(3,3), padding='same', strides=(2,2))\n",
    "        self.lRelu6 = layers.LeakyReLU()\n",
    "        self.drop6 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"\n",
    "        Runs the encoding inference for `inputs`.\n",
    "        \n",
    "        Inputs:\n",
    "        -inputs: 4D-tensor with dimension (batch_size, self.input_dim).\n",
    "        \"\"\"\n",
    "        \n",
    "        z = self.conv1(inputs)\n",
    "        z = self.lRelu1(z)\n",
    "        z = self.drop1(z)\n",
    "        \n",
    "        z = self.conv2(z)\n",
    "        z = self.lRelu2(z)\n",
    "        z = self.drop2(z)\n",
    "        \n",
    "        z = self.conv3(z)\n",
    "        z = self.lRelu3(z)\n",
    "        z = self.drop3(z)\n",
    "        \n",
    "        z = self.conv4(z)\n",
    "        z = self.lRelu4(z)\n",
    "        z = self.drop4(z)\n",
    "        \n",
    "        z = self.conv5(z)\n",
    "        z = self.lRelu5(z)\n",
    "        z = self.drop5(z)\n",
    "        \n",
    "        z = self.conv6(z)\n",
    "        z = self.lRelu6(z)\n",
    "        z = self.drop6(z)\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Function defining convolution decoder layer</b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDecoder(layers.Layer):\n",
    "    \"\"\"\n",
    "    Convolutional Decoder Layer Class.\n",
    "    Converts z, the encoded digit vector, back into a readable digit.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_shape, dropout_rate=0.0, name='decoder', **kwargs):\n",
    "        \"\"\"\n",
    "        Initializes the decoder architecture and saves it as a local attribute.\n",
    "        \n",
    "        Input:\n",
    "        -input_shape: 3D-tuple with (rows, cols, channels) input representation.\n",
    "        \n",
    "        Returns nothing.\n",
    "        \"\"\"\n",
    "        super(ConvDecoder, self).__init__(name=name, input_shape=input_shape, **kwargs)\n",
    "        \n",
    "        self.convT1 = layers.Conv2DTranspose(512, kernel_size=(3,3), strides=(2,2), padding='same')\n",
    "        self.lRelu1 = layers.LeakyReLU()\n",
    "        self.drop1 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        self.convT2 = layers.Conv2DTranspose(256, kernel_size=(3,3), strides=(2,2), padding='same')\n",
    "        self.lRelu2 = layers.LeakyReLU()\n",
    "        self.drop2 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        self.convT3 = layers.Conv2DTranspose(128, kernel_size=(3,3), strides=(2,2), padding='same')\n",
    "        self.lRelu3 = layers.LeakyReLU()\n",
    "        self.drop3 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        self.convT4 = layers.Conv2DTranspose(64, kernel_size=(3,3), strides=(2,2), padding='same')\n",
    "        self.lRelu4 = layers.LeakyReLU()\n",
    "        self.drop4 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        self.convT5 = layers.Conv2DTranspose(32, kernel_size=(3,3), strides=(2,2), padding='same')\n",
    "        self.lRelu5 = layers.LeakyReLU()\n",
    "        self.drop5 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        self.convT6 = layers.Conv2DTranspose(1, kernel_size=(3,3), strides=(2,2), padding='same', \n",
    "                                             activation='sigmoid')\n",
    "        \n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"\n",
    "        Runs the encoding inference for `inputs`.\n",
    "        \n",
    "        Inputs:\n",
    "        -inputs: 4D-tensor with dimension (batch_size, self.input_dim).\n",
    "        \"\"\"\n",
    "        \n",
    "        x = self.convT1(inputs)\n",
    "        x = self.lRelu1(x)\n",
    "        x = self.drop1(x)\n",
    "        \n",
    "        x = self.convT2(x)\n",
    "        x = self.lRelu2(x)\n",
    "        x = self.drop2(x)\n",
    "        \n",
    "        x = self.convT3(x)\n",
    "        x = self.lRelu3(x)\n",
    "        x = self.drop3(x)\n",
    "        \n",
    "        x = self.convT4(x)\n",
    "        x = self.lRelu4(x)\n",
    "        x = self.drop4(x)\n",
    "        \n",
    "        x = self.convT5(x)\n",
    "        x = self.lRelu5(x)\n",
    "        x = self.drop5(x)\n",
    "        \n",
    "        x = self.convT6(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Function to create Conditional Encoder: Noisy Image to Label </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create Conditional Model\n",
    "def create_cond_encoder(loss):\n",
    "\n",
    "    # Create Conditional Encoder\n",
    "    input_encoder_img = layers.Input(input_shape_img)\n",
    "    input_encoder_stats = layers.Input(input_shape_stats)\n",
    "    \n",
    "    norm_encoder_img = layers.BatchNormalization()(input_encoder_img)\n",
    "    norm_encoder_stats = layers.BatchNormalization()(input_encoder_stats)\n",
    "    \n",
    "    x = ConvEncoder(input_shape_img)(norm_encoder_img)\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.concatenate([x, norm_encoder_stats])\n",
    "    \n",
    "    x = layers.Dense(2048)(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "    x = layers.Dense(1024)(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "    \n",
    "    # Output later of the conditional encoder\n",
    "    latent_z = layers.Dense(latent_z_dim_labels, activation='sigmoid')(x)\n",
    "    \n",
    "    \n",
    "    # Conditional Encoder Model\n",
    "    encoder = tf.keras.Model([input_encoder_img, input_encoder_stats], latent_z, name='Cond_Encoder')\n",
    "    \n",
    "    # Define Optimizer\n",
    "    optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "    \n",
    "    # Compile the model\n",
    "    encoder.compile(optimizer, loss=loss)\n",
    "    \n",
    "    # Display the model summary\n",
    "    display(encoder.summary())\n",
    "    \n",
    "    \n",
    "    # Return conditional encoder\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Function to create Decoder: Label to Noiseless Image </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decoder Model\n",
    "def create_decoder(loss):\n",
    "\n",
    "    # Create Decoder\n",
    "    input_decoder_labels = layers.Input(latent_z_dim_labels)\n",
    "    \n",
    "    x = layers.Dense(1024)(input_decoder_labels)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "    x = layers.Dense(2048)(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "    x = layers.Reshape(latent_dim)(x)\n",
    "    recon = ConvDecoder(latent_dim)(x)\n",
    "    \n",
    "    \n",
    "    # Decoder Model\n",
    "    decoder = tf.keras.Model(input_decoder_labels, recon, name='Decoder')\n",
    "    \n",
    "    # Define Optimizer\n",
    "    optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "    \n",
    "    # Compile the model\n",
    "    decoder.compile(optimizer, loss=loss)\n",
    "    \n",
    "    # Display the model summary\n",
    "    display(decoder.summary())\n",
    "    \n",
    "    \n",
    "    # Return decoder\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Function to create Conditional Auto-encoder: Noisy Image to Noiseless Image </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CAE(encoder, decoder):\n",
    "    input_encoder_img = layers.Input(input_shape_img)\n",
    "    input_encoder_stats = layers.Input(input_shape_stats)\n",
    "    \n",
    "    labels = encoder([input_encoder_img, input_encoder_stats])\n",
    "    recons = decoder(labels)\n",
    "    \n",
    "    # Conditional AE Model\n",
    "    CAE = tf.keras.Model([input_encoder_img, input_encoder_stats], [recons, labels], name='CAE')\n",
    "    \n",
    "    # Define Optimizer\n",
    "    optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "    \n",
    "    # Define Loss\n",
    "    loss = {\n",
    "        'Cond_Encoder': 'binary_crossentropy',\n",
    "        'Decoder': 'binary_crossentropy'\n",
    "    }\n",
    "    \n",
    "    # Define Loss\n",
    "    lossWeights = {\n",
    "        'Cond_Encoder': 5.0, \n",
    "        'Decoder': 1.0}\n",
    "    \n",
    "    # Compile the model\n",
    "    CAE.compile(optimizer, loss=loss, loss_weights=lossWeights)\n",
    "    \n",
    "    # Display the model summary\n",
    "    display(CAE.summary())\n",
    "    \n",
    "    # Return reverse decoder\n",
    "    return CAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Function to train Conditional Auto-encoder </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CAE(CAE, set=1):\n",
    "    # Scheduler for learning rate\n",
    "    def scheduler(epoch):\n",
    "        if epoch < 5:\n",
    "            return 0.001\n",
    "        else:\n",
    "            return 0.001 * np.exp(0.1 * (5 - epoch))\n",
    "\n",
    "    # Check if model is pretrained\n",
    "    try:\n",
    "        CAE.load_weights(paths[set-1])\n",
    "        CAE.trainable = False\n",
    "        print(\"Training Loss:   {}\".format(CAE.evaluate(tr_ds_AE)))\n",
    "        print(\"Validation Loss: {}\".format(CAE.evaluate(val_ds_AE)))\n",
    "        \n",
    "    # Train if model is not pre-trained\n",
    "    except:\n",
    "        CAE.trainable = True\n",
    "        history = CAE.fit(\n",
    "            tr_ds_AE, \n",
    "            epochs=epochs, \n",
    "            verbose=1,\n",
    "            validation_data=val_ds_AE,\n",
    "            callbacks=[\n",
    "                EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "                LearningRateScheduler(scheduler)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        CAE.save_weights(paths[set-1])\n",
    "        CAE.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Function to generating reconstructed images for visual inspection </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_images(CAE, val_ds_AE):\n",
    "    test = val_ds_AE.take(1)\n",
    "    (images, stats), (clean, labels) = next(iter(test))\n",
    "    pred_img, pred_lab = CAE.predict([images, stats])\n",
    "    pred = pred_img.reshape(pred_img.shape[:-1])\n",
    "\n",
    "    fig, ax = plt.subplots(1,8, figsize=(20,3))\n",
    "    plt.suptitle(\"Generated Images\", fontsize=25)\n",
    "    for j in range(8):\n",
    "        ax[j].imshow(pred[idx[j]])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1,8, figsize=(20,3))\n",
    "    plt.suptitle(\"Clean Images\", fontsize=25)\n",
    "    for j in range(8):\n",
    "        ax[j].imshow(clean[idx[j]].numpy().reshape(64,64))\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(1,8, figsize=(20,3))\n",
    "    plt.suptitle(\"Original Noisy Images\", fontsize=25)\n",
    "    for j in range(8):\n",
    "        ax[j].imshow(images[idx[j],:,:,0].numpy())\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1,8, figsize=(20,3))\n",
    "    plt.suptitle(\"Residual Unscaled (Clean minus Generated)\", fontsize=25)\n",
    "    for j in range(8):\n",
    "        ax[j].imshow(np.abs(clean[idx[j]].numpy().reshape(64,64)-pred[idx[j]]), vmin=0, vmax=1)\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(1,8, figsize=(20,3))\n",
    "    plt.suptitle(\"Residual Scaled Absolute Values (Clean minus Generated scaled to {0,1})\", fontsize=25)\n",
    "    for j in range(8):\n",
    "        ax[j].imshow(np.abs(clean[idx[j]].numpy().reshape(64,64)-pred[idx[j]]))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1,8, figsize=(20,3))\n",
    "    plt.suptitle(\"Residual Scaled (Clean minus Generated sclaed to {0,1})\", fontsize=25)\n",
    "    for j in range(8):\n",
    "        ax[j].imshow((clean[idx[j]].numpy().reshape(64,64)-pred[idx[j]]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Function for Variance Analysis of the Labels </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def variance_analysis(CAE, ds, scaler, label_v, test=False):\n",
    "    np.set_printoptions(precision=5, suppress=True)\n",
    "    \n",
    "    _, pred = CAE.predict(ds)\n",
    "    error = unnorm_label(pred, scaler) - unnorm_label(label_v, scaler)\n",
    "    \n",
    "    bias = error.mean(axis=0)\n",
    "    MSE = (error**2).mean(axis=0)\n",
    "    RMSE = np.sqrt(MSE)\n",
    "\n",
    "    results = pd.DataFrame({'Bias': bias, 'RMSE': RMSE, },\n",
    "                          index=['Flux', 'Sersic Index', 'Sersic Radius', 'g1', 'g2'])\n",
    "    \n",
    "    if not test:\n",
    "        label_var = (unnorm_label(label_v, scaler).std(axis=0))**2\n",
    "        unexplained_var = MSE/label_var\n",
    "        results['Un-Explained Variance'] = unexplained_var\n",
    "        results['Explained Variance'] = 1 -unexplained_var\n",
    "        \n",
    "    display(results)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Function for comparing True Labels with Predicted Labels </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def true_vs_pred(pred):\n",
    "    titles = ['Flux', 'Sersic Index', 'Sersic Radius', 'g1']\n",
    "\n",
    "    fig, ax = plt.subplots(2,2, figsize=(20, 20))\n",
    "\n",
    "    for i in range(4):\n",
    "        im = ax[i//2, i%2].scatter(label_val[:5000,i], pred[:5000,i], c=snr_val[:5000], marker='.', cmap='RdYlBu')\n",
    "        fig.colorbar(im, ax=ax[i//2, i%2])\n",
    "        ax[i//2, i%2].set_title(titles[i], fontsize=20)\n",
    "        ax[i//2, i%2].set_xlabel('True Value', fontsize=16)\n",
    "        ax[i//2, i%2].set_ylabel('Predicted Value', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 3: Define Global Variables </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to save model weight\n",
    "paths = [\n",
    "    './model/CAE_1e',\n",
    "    './model/CAE_2e',\n",
    "    './model/CAE_3e'\n",
    "]\n",
    "\n",
    "# Batch Size\n",
    "batch_size = 256\n",
    "\n",
    "# Shuffling Parameter for Pipeline\n",
    "shuffle = 1024\n",
    "\n",
    "# Encoder Input Dimension\n",
    "input_shape_img = (64,64,7)\n",
    "input_shape_stats = (4,)\n",
    "\n",
    "# Dropout rate for dense layers\n",
    "dropout = 0.5\n",
    "\n",
    "# Encoder Output dimension - Decoder Input Dimension\n",
    "latent_z_dim_labels = 5\n",
    "\n",
    "# Decoder latent dimension\n",
    "latent_dim = (1,1,2048)\n",
    "\n",
    "# Define Model loss\n",
    "enc_loss = losses.BinaryCrossentropy()\n",
    "dec_loss = losses.BinaryCrossentropy()\n",
    "\n",
    "# Number of Training Epochs\n",
    "epochs = 50\n",
    "\n",
    "# 8 random numbers for image visualization\n",
    "idx = np.random.randint(batch_size, size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> Part 1 </div> \n",
    "\n",
    "<div style=\"border: 3px solid #800080; padding: 10px\"> \n",
    "\n",
    "## GalSim Images with fixed Sigma and fixed PSF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 1: Load the Training and Validation dataset with fixed noise and fixed PSF </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available variables:\n",
      "    img\n",
      "    img_nonoise\n",
      "    label\n",
      "    psf_r\n",
      "    snr\n",
      "    sigma\n",
      "    train_test\n",
      "    psf_image\n",
      "\n",
      "Image Shape            = (200000, 64, 64)\n",
      "No-noise Image Shape   = (200000, 64, 64)\n",
      "Label Shape            = (200000, 5)\n",
      "SNR Shape              = (200000,)\n",
      "Sigma Shape            = (200000,)\n",
      "PSF-R Shape            = (200000,)\n",
      "Pixel Std-dev Shape    = (200000,)\n",
      "Pixel Mean Shape       = (200000,)\n",
      "PSF Image Shape        = (1, 64, 64)\n",
      "\n",
      "Number of Training Points:    180000\n",
      "Number of Validation Points:  20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the data set\n",
    "(image_train, image_val,\n",
    " image_nonoise_train,  image_nonoise_val,\n",
    " label_train,  label_val,\n",
    " psf_train, psf_val,\n",
    " snr_train, snr_val,\n",
    " sigma_train, sigma_val,\n",
    " psf_img_train, psf_img_val,\n",
    " stats_train, stats_val,\n",
    " mean_train, mean_val) = load_data(set=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 2: Normalize the Labels, Sigma, PSF, Stats & Noiseless Images </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Normalize Labels, PSF, Sigma, Stats </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the label, etc.\n",
    "label_train,  label_val, scaler1 = norm_label(label_train, label_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Normalize the Images </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the Images\n",
    "image_nonoise_train, image_nonoise_val = norm_image(image_nonoise_train, image_nonoise_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 3: Create Data Pipeline </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Function to Load Data and Divide data into Training and Validation Set </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensorflow Dataset\n",
    "training, validation = create_dataset(set=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Create dataset pipeline </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pipeline for Conditional Auto-encoder\n",
    "tr_ds_AE = training.map(\n",
    "    pipeline_noisy_image_to_clean_image).shuffle(shuffle).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_ds_AE = validation.map(\n",
    "    pipeline_noisy_image_to_clean_image).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 4: Create Conditional Auto-encoder </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Cond_Encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 64, 7)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 7)    28          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder (ConvEncoder)           (None, 1, 1, 2048)   11008960    batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 4)            16          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2052)         0           flatten[0][0]                    \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048)         4204544     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 2048)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 2048)         0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 5)            5125        dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 17,316,849\n",
      "Trainable params: 17,316,827\n",
      "Non-trainable params: 22\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 5)]               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              6144      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2048)              2099200   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 1, 1, 2048)        0         \n",
      "_________________________________________________________________\n",
      "decoder (ConvDecoder)        (None, 64, 64, 1)         11005185  \n",
      "=================================================================\n",
      "Total params: 13,110,529\n",
      "Trainable params: 13,110,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CAE\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 64, 64, 7)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Cond_Encoder (Model)            (None, 5)            17316849    input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Decoder (Model)                 (None, 64, 64, 1)    13110529    Cond_Encoder[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 30,427,378\n",
      "Trainable params: 30,427,356\n",
      "Non-trainable params: 22\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clear Session\n",
    "K.clear_session()\n",
    "\n",
    "# Create Conditional Encoder\n",
    "encoder = create_cond_encoder(enc_loss)\n",
    "\n",
    "# Create Decoder\n",
    "decoder = create_decoder(dec_loss)\n",
    "\n",
    "# Create Conditional Autoencoder\n",
    "CAE = create_CAE(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 5: Train Conditional Auto-encoder </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "      1/Unknown - 10s 10s/stepWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: \n",
      "      1/Unknown - 10s 10s/step"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_5 to have shape (4,) but got array with shape (2,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6c475b5e8a15>\u001b[0m in \u001b[0;36mtrain_CAE\u001b[0;34m(CAE, set)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mCAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mCAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m    180\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m         \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m         \u001b[0msave_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m    872\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mthis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_CheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./model/CAE_1e",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-078c82df0421>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_CAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-6c475b5e8a15>\u001b[0m in \u001b[0;36mtrain_CAE\u001b[0;34m(CAE, set)\u001b[0m\n\u001b[1;32m     24\u001b[0m             callbacks=[\n\u001b[1;32m     25\u001b[0m                 \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             ]\n\u001b[1;32m     28\u001b[0m         )\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    501\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 408\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[0;34m(input_iterator)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     outputs = strategy.experimental_run_v2(\n\u001b[0;32m---> 73\u001b[0;31m         per_replica_function, args=(model, x, y, sample_weights))\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Out of PerReplica outputs reduce or pick values to return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     all_outputs = dist_utils.unwrap_output_dict(\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mexperimental_run_v2\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    758\u001b[0m       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\n\u001b[1;32m    759\u001b[0m                                 convert_by_default=False)\n\u001b[0;32m--> 760\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2130\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2132\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    251\u001b[0m   x, y, sample_weights = model._standardize_user_data(\n\u001b[1;32m    252\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m       extract_tensors_from_dataset=True)\n\u001b[0m\u001b[1;32m    254\u001b[0m   \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m   \u001b[0;31m# If `model._distribution_strategy` is True, then we are in a replica context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    572\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    575\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_5 to have shape (4,) but got array with shape (2,)"
     ]
    }
   ],
   "source": [
    "train_CAE(CAE, set=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 6: Performance Analysis </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Generating reconstructed images for visual inspection </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_images(CAE, val_ds_AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Variance Analysis for Label </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = variance_analysis(CAE, val_ds_AE, scaler1, label_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Comparing True Labels with Predicted Labels </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vs_pred(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> End of Part 1 </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> Part 2 </div> \n",
    "\n",
    "<div style=\"border: 3px solid #800080; padding: 10px\"> \n",
    "\n",
    "## GalSim Images with variable Sigma and fixed PSF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 1: Load the Training and Validation dataset with variable noise and fixed PSF </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data set\n",
    "(image_train, image_val,\n",
    " image_nonoise_train,  image_nonoise_val,\n",
    " label_train,  label_val,\n",
    " psf_train, psf_val,\n",
    " snr_train, snr_val,\n",
    " sigma_train, sigma_val,\n",
    " psf_img_train, psf_img_val,\n",
    " stats_train, stats_val,\n",
    " mean_train, mean_val) = load_data(set=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 2: Normalize the Labels, Sigma, PSF, Stats & Noiseless Images </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Normalize Labels, PSF, Sigma, Stats </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the label, etc.\n",
    "label_train,  label_val, scaler2 = norm_label(label_train, label_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Normalize the Images </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the Images\n",
    "image_nonoise_train, image_nonoise_val = norm_image(image_nonoise_train, image_nonoise_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 3: Create Data Pipeline </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Function to Load Data and Divide data into Training and Validation Set </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensorflow Dataset\n",
    "training, validation = create_dataset(set=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Create dataset pipeline </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pipeline for Conditional Auto-encoder\n",
    "tr_ds_AE = training.map(\n",
    "    pipeline_noisy_image_to_clean_image).shuffle(shuffle).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_ds_AE = validation.map(\n",
    "    pipeline_noisy_image_to_clean_image).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 4: Train Conditional Auto-encoder </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_CAE(CAE, set=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 5: Performance Analysis </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Generating reconstructed images for visual inspection </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_images(CAE, val_ds_AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Variance Analysis for Label </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = variance_analysis(CAE, val_ds_AE, scaler2, label_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Comparing True Labels with Predicted Labels </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vs_pred(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> End of Part 2 </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> Part 3 </div> \n",
    "\n",
    "<div style=\"border: 3px solid #800080; padding: 10px\"> \n",
    "\n",
    "## GalSim Images with variable Sigma and variable PSF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 1: Load the Training and Validation dataset with variable noise and variable PSF </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data set\n",
    "(image_train, image_val,\n",
    " image_nonoise_train,  image_nonoise_val,\n",
    " label_train,  label_val,\n",
    " psf_train, psf_val,\n",
    " snr_train, snr_val,\n",
    " sigma_train, sigma_val,\n",
    " psf_img_train, psf_img_val,\n",
    " stats_train, stats_val,\n",
    " mean_train, mean_val) = load_data(set=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 2: Normalize the Labels, Sigma, PSF, Stats & Noiseless Images </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Normalize Labels, PSF, Sigma, Stats </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the label, etc.\n",
    "label_train,  label_val, scaler3 = norm_label(label_train, label_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Normalize the Images </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the Images\n",
    "image_nonoise_train, image_nonoise_val = norm_image(image_nonoise_train, image_nonoise_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 3: Create Data Pipeline </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Function to Load Data and Divide data into Training and Validation Set </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensorflow Dataset\n",
    "training, validation = create_dataset(set=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Create dataset pipeline </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pipeline for Conditional Auto-encoder\n",
    "tr_ds_AE = training.map(\n",
    "    pipeline_noisy_image_to_clean_image).shuffle(shuffle).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_ds_AE = validation.map(\n",
    "    pipeline_noisy_image_to_clean_image).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 4: Train Conditional Auto-encoder </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_CAE(CAE, set=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 5: Performance Analysis </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Generating reconstructed images for visual inspection </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_images(CAE, val_ds_AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Variance Analysis for Label </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = variance_analysis(CAE, val_ds_AE, scaler3, label_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Comparing True Labels with Predicted Labels </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vs_pred(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> End of Part 3 </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> Part 4 </div> \n",
    "\n",
    "<div style=\"border: 3px solid #800080; padding: 10px\"> \n",
    "\n",
    "## Test Dataset:  SNR = 30\n",
    "\n",
    "\n",
    "| \\# Samples | Avg. SNR | Flux [$10^5$] | Sersic index | Sersic radius | g1     | g2   | PSF  | Noise | Link                                                |\n",
    "| ---------- | -------- | ------------- | ------------ | ------------- | ------ | ---- | ---- | ----- | --------------------------------------------------- |\n",
    "| 10,000     | 29.95    | 1.0           | 3.0          | 0.3           | -0.069 | 0.15 | 0.5  | 400   | https://s3.amazonaws.com/measure.galaxies/snr30.npz |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 1: Load the Testing dataset with average SNR of 30 </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data set\n",
    "(image_test,\n",
    " image_nonoise_test,\n",
    " label_test,\n",
    " psf_test,\n",
    " snr_test,\n",
    " sigma_test,\n",
    " psf_img_test,\n",
    " stats_test,\n",
    " mean_test) = load_data(set=4, test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 2: Normalize the data </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Normalize the labels\n",
    "label_test = norm_label(label_test, scaler=scaler2)\n",
    "\n",
    "# Normalize the Images\n",
    "image_nonoise_test = norm_image(image_nonoise_test, test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 3: Create Data Pipeline </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Create Dataset </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensorflow Dataset\n",
    "testing = create_dataset(test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Create dataset pipeline </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = testing.map(\n",
    "    pipeline_noisy_image_to_clean_image).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 4: Load Conditional Auto-encoder trained with variable Noise and fixed PSF </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAE.load_weights(paths[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 5: Performance Analysis </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Generating reconstructed images for visual inspection </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_images(CAE, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Variance Analysis for Label </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = variance_analysis(CAE, test_ds, scaler2, label_test, test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> End of Part 4 </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> Part 5 </div> \n",
    "\n",
    "<div style=\"border: 3px solid #800080; padding: 10px\"> \n",
    "\n",
    "## Test Dataset:  SNR = 60\n",
    "\n",
    "\n",
    "| \\# Samples | Avg. SNR | Flux [$10^5$] | Sersic index | Sersic radius | g1     | g2   | PSF  | Noise | Link                                                |\n",
    "| ---------- | -------- | ------------- | ------------ | ------------- | ------ | ---- | ---- | ----- | --------------------------------------------------- |\n",
    "| 10,000     | 59.90    | 1.0           | 3.0          | 0.3           | -0.069 | 0.15 | 0.5  | 200   | https://s3.amazonaws.com/measure.galaxies/snr60.npz |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 1: Load the Testing dataset with average SNR of 30 </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read the data set\n",
    "(image_test,\n",
    " image_nonoise_test,\n",
    " label_test,\n",
    " psf_test,\n",
    " snr_test,\n",
    " sigma_test,\n",
    " psf_img_test,\n",
    " stats_test,\n",
    " mean_test) = load_data(set=5, test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 2: Normalize the data </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Normalize the labels\n",
    "label_test = norm_label(label_test, scaler=scaler1)\n",
    "\n",
    "# Normalize the Images\n",
    "image_nonoise_test = norm_image(image_nonoise_test, test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 3: Create Data Pipeline </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Create Dataset </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensorflow Dataset\n",
    "testing = create_dataset(test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Create dataset pipeline </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = testing.map(\n",
    "    pipeline_noisy_image_to_clean_image).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 4: Load Conditional Auto-encoder trained with variable Noise and fixed PSF </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAE.load_weights(paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class='exercise'> <b> Step 5: Performance Analysis </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Generating reconstructed images for visual inspection </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_images(CAE, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='gc'> <b> Variance Analysis for Label </b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = variance_analysis(CAE, test_ds, scaler1, label_test, test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> End of Part 5 </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div class=\"theme\"> Summary </div> \n",
    "\n",
    "<div style=\"border: 3px solid #800080; padding: 10px\"> \n",
    "    \n",
    "### ***Shape and Brightness of a Galaxy***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\">  End Of Project\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
